<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RTX 5080 GPU Memory Predictor</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: linear-gradient(135deg, #0a0a0a 0%, #1a1a1a 100%);
            color: #e0e0e0;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            min-height: 100vh;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background: linear-gradient(45deg, #76b900, #a3d900);
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(118, 185, 0, 0.3);
        }

        .header h1 {
            color: #000;
            font-size: 2.5rem;
            font-weight: bold;
            margin-bottom: 10px;
            text-shadow: none;
        }

        .header p {
            color: #222;
            font-size: 1.1rem;
            font-weight: 500;
        }

        .main-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }

        @media (max-width: 768px) {
            .main-content {
                grid-template-columns: 1fr;
            }
        }

        .panel {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            padding: 20px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        .panel h2 {
            color: #76b900;
            margin-bottom: 15px;
            font-size: 1.5rem;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .icon {
            width: 24px;
            height: 24px;
            fill: #76b900;
        }

        textarea {
            width: 100%;
            height: 300px;
            background: rgba(0, 0, 0, 0.4);
            border: 1px solid rgba(118, 185, 0, 0.3);
            border-radius: 10px;
            color: #e0e0e0;
            padding: 15px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            resize: vertical;
            outline: none;
            transition: border-color 0.3s ease;
        }

        textarea:focus {
            border-color: #76b900;
            box-shadow: 0 0 10px rgba(118, 185, 0, 0.2);
        }

        .controls {
            display: flex;
            gap: 10px;
            margin: 15px 0;
            flex-wrap: wrap;
        }

        .input-group {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }

        .input-group label {
            color: #76b900;
            font-size: 0.9rem;
            font-weight: 500;
        }

        .input-group input {
            background: rgba(0, 0, 0, 0.4);
            border: 1px solid rgba(118, 185, 0, 0.3);
            border-radius: 5px;
            color: #e0e0e0;
            padding: 8px 12px;
            width: 120px;
            outline: none;
            transition: border-color 0.3s ease;
        }

        .input-group input:focus {
            border-color: #76b900;
        }

        button {
            background: linear-gradient(45deg, #76b900, #a3d900);
            color: #000;
            border: none;
            padding: 10px 20px;
            border-radius: 8px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(118, 185, 0, 0.3);
        }

        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(118, 185, 0, 0.4);
        }

        .template-buttons {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            margin: 15px 0;
        }

        .template-btn {
            background: rgba(118, 185, 0, 0.1);
            color: #76b900;
            border: 1px solid #76b900;
            padding: 8px 15px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: all 0.3s ease;
        }

        .template-btn:hover {
            background: rgba(118, 185, 0, 0.2);
        }

        .memory-breakdown {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            padding: 20px;
            margin-top: 15px;
        }

        .memory-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .memory-item:last-child {
            border-bottom: none;
            font-weight: bold;
            font-size: 1.1rem;
            margin-top: 10px;
            padding-top: 15px;
            border-top: 2px solid rgba(118, 185, 0, 0.3);
        }

        .memory-value {
            font-family: 'Courier New', monospace;
            font-weight: bold;
        }

        .warning {
            background: linear-gradient(45deg, #ff4444, #cc0000);
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            display: none;
            animation: pulse 2s infinite;
        }

        .success {
            background: linear-gradient(45deg, #44ff44, #00cc00);
            color: #000;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            display: none;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .gpu-specs {
            background: rgba(118, 185, 0, 0.1);
            border: 1px solid rgba(118, 185, 0, 0.3);
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            text-align: center;
        }

        .gpu-specs h3 {
            color: #76b900;
            margin-bottom: 10px;
        }

        .progress-bar {
            background: rgba(0, 0, 0, 0.4);
            border-radius: 10px;
            height: 20px;
            margin: 10px 0;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            border-radius: 10px;
            transition: all 0.5s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #000;
            font-weight: bold;
            font-size: 0.8rem;
        }

        .details-section {
            grid-column: 1 / -1;
            margin-top: 20px;
        }

        .model-layers {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            padding: 15px;
            max-height: 300px;
            overflow-y: auto;
        }

        .layer-item {
            display: grid;
            grid-template-columns: 2fr 1fr 1fr 1fr;
            gap: 15px;
            padding: 8px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
        }

        .layer-header {
            font-weight: bold;
            color: #76b900;
            background: rgba(118, 185, 0, 0.1);
            padding: 10px;
            margin: -15px -15px 10px -15px;
            border-radius: 10px 10px 0 0;
        }

        .rtx-badge {
            display: inline-block;
            background: linear-gradient(45deg, #76b900, #a3d900);
            color: #000;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.8rem;
            font-weight: bold;
            margin-left: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>
                <svg class="icon" viewBox="0 0 24 24">
                    <path d="M12 2L2 7V17L12 22L22 17V7L12 2M12 4.44L19.2 8.4L12 12.36L4.8 8.4L12 4.44M4 10.24L11 14.2V19.76L4 15.8V10.24M13 19.76V14.2L20 10.24V15.8L13 19.76Z"/>
                </svg>
                RTX 5080 GPU Memory Predictor
                <span class="rtx-badge">16GB GDDR7</span>
            </h1>
            <p>Predict PyTorch model memory usage before training - Prevent OOM errors</p>
            <div style="margin-top: 15px;">
                <a href="tools.html" style="color: #222; text-decoration: none; margin-right: 20px; font-weight: bold;">‚Üê All Tools</a>
                <a href="index.html" style="color: #222; text-decoration: none; font-weight: bold;">üîç Try Tensor Debugger</a>
            </div>
        </div>

        <div class="main-content">
            <div class="panel">
                <h2>
                    <svg class="icon" viewBox="0 0 24 24">
                        <path d="M14,2H6A2,2 0 0,0 4,4V20A2,2 0 0,0 6,22H18A2,2 0 0,0 20,20V8L14,2M18,20H6V4H13V9H18V20Z"/>
                    </svg>
                    Model Code Input
                </h2>
                
                <div class="template-buttons">
                    <button class="template-btn" onclick="loadTemplate('gpt2')">GPT-2 Large</button>
                    <button class="template-btn" onclick="loadTemplate('vit')">Vision Transformer</button>
                    <button class="template-btn" onclick="loadTemplate('resnet')">ResNet-50</button>
                    <button class="template-btn" onclick="loadTemplate('bert')">BERT-Base</button>
                    <button class="template-btn" onclick="loadTemplate('lstm')">LSTM RNN</button>
                </div>

                <textarea id="modelCode" placeholder="Paste your PyTorch model code here...

Example:
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, 3)
        self.conv2 = nn.Conv2d(64, 128, 3)
        self.fc1 = nn.Linear(128 * 56 * 56, 1024)
        self.fc2 = nn.Linear(1024, 10)
    
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        return self.fc2(x)"></textarea>

                <div class="controls">
                    <div class="input-group">
                        <label>Batch Size</label>
                        <input type="number" id="batchSize" value="32" min="1">
                    </div>
                    <div class="input-group">
                        <label>Input Size</label>
                        <input type="text" id="inputSize" value="3,224,224" placeholder="C,H,W">
                    </div>
                    <div class="input-group">
                        <label>Precision</label>
                        <select id="precision" style="background: rgba(0,0,0,0.4); border: 1px solid rgba(118,185,0,0.3); border-radius: 5px; color: #e0e0e0; padding: 8px 12px;">
                            <option value="32">Float32</option>
                            <option value="16">Float16</option>
                            <option value="8">Int8</option>
                        </select>
                    </div>
                </div>

                <button onclick="analyzeModel()" style="width: 100%;">
                    <svg class="icon" viewBox="0 0 24 24" style="fill: #000; margin-right: 8px;">
                        <path d="M12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0,0 22,12A10,10 0 0,0 12,2M7.07,18.28C7.5,17.38 8.12,16.5 8.91,15.77C9.71,15.04 10.69,14.5 11.73,14.21C12.27,14.05 12.85,13.93 13.45,13.93C13.78,13.93 14.11,13.96 14.44,14.03C15.44,14.25 16.4,14.69 17.25,15.31C17.87,15.73 18.42,16.25 18.87,16.85C18.97,16.97 19.07,17.1 19.16,17.23C19.09,17.85 18.98,18.46 18.82,19.05C18.1,18.95 17.37,18.89 16.64,18.89C15.04,18.89 13.45,19.11 11.91,19.54C10.73,19.85 9.6,20.3 8.54,20.86C8.05,19.67 7.5,18.5 7.07,18.28M12,15.45C11.57,15.45 11.25,15.12 11.25,14.69C11.25,14.26 11.57,13.93 12,13.93C12.43,13.93 12.75,14.26 12.75,14.69C12.75,15.12 12.43,15.45 12,15.45M12,8.5C12.21,8.5 12.39,8.61 12.46,8.8L14.25,13.58C14.33,13.81 14.21,14.06 13.98,14.14C13.95,14.15 13.92,14.15 13.88,14.15C13.69,14.15 13.5,14.04 13.43,13.85L12.85,12.37H11.15L10.57,13.85C10.5,14.04 10.31,14.15 10.12,14.15C10.08,14.15 10.05,14.15 10.02,14.14C9.79,14.06 9.67,13.81 9.75,13.58L11.54,8.8C11.61,8.61 11.79,8.5 12,8.5M12,9.76L11.47,11.12H12.53L12,9.76Z"/>
                    </svg>
                    Analyze Memory Usage
                </button>
            </div>

            <div class="panel">
                <h2>
                    <svg class="icon" viewBox="0 0 24 24">
                        <path d="M12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0,0 22,12A10,10 0 0,0 12,2M12,4A8,8 0 0,1 20,12A8,8 0 0,1 12,20A8,8 0 0,1 4,12A8,8 0 0,1 12,4M12,6A6,6 0 0,0 6,12A6,6 0 0,0 12,18A6,6 0 0,0 18,12A6,6 0 0,0 12,6M12,8A4,4 0 0,1 16,12A4,4 0 0,1 12,16A4,4 0 0,1 8,12A4,4 0 0,1 12,8Z"/>
                    </svg>
                    Memory Analysis
                </h2>

                <div class="gpu-specs">
                    <h3>RTX 5080 Specifications</h3>
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px; text-align: left;">
                        <div>Memory: <strong>16GB GDDR7</strong></div>
                        <div>Bandwidth: <strong>1008 GB/s</strong></div>
                        <div>CUDA Cores: <strong>10,752</strong></div>
                        <div>RT Cores: <strong>84 (3rd Gen)</strong></div>
                    </div>
                </div>

                <div class="warning" id="warning">
                    ‚ö†Ô∏è <strong>MEMORY WARNING!</strong><br>
                    Your model exceeds RTX 5080 memory capacity. Consider:
                    ‚Ä¢ Reduce batch size
                    ‚Ä¢ Use gradient checkpointing
                    ‚Ä¢ Switch to mixed precision (FP16)
                    ‚Ä¢ Use model parallelism
                </div>

                <div class="success" id="success">
                    ‚úÖ <strong>MEMORY OK!</strong><br>
                    Your model fits comfortably in RTX 5080 memory with safety margin.
                </div>

                <div class="progress-bar">
                    <div class="progress-fill" id="memoryProgress" style="width: 0%; background: linear-gradient(45deg, #76b900, #a3d900);">
                        0%
                    </div>
                </div>

                <div class="memory-breakdown" id="memoryBreakdown">
                    <div class="memory-item">
                        <span>Model Parameters:</span>
                        <span class="memory-value" id="paramMemory">-- MB</span>
                    </div>
                    <div class="memory-item">
                        <span>Gradients:</span>
                        <span class="memory-value" id="gradMemory">-- MB</span>
                    </div>
                    <div class="memory-item">
                        <span>Optimizer States (Adam):</span>
                        <span class="memory-value" id="optimMemory">-- MB</span>
                    </div>
                    <div class="memory-item">
                        <span>Activations (est):</span>
                        <span class="memory-value" id="activMemory">-- MB</span>
                    </div>
                    <div class="memory-item">
                        <span>Total Memory Usage:</span>
                        <span class="memory-value" id="totalMemory">-- MB</span>
                    </div>
                </div>
            </div>
        </div>

        <div class="panel details-section">
            <h2>
                <svg class="icon" viewBox="0 0 24 24">
                    <path d="M12,15.5A3.5,3.5 0 0,1 8.5,12A3.5,3.5 0 0,1 12,8.5A3.5,3.5 0 0,1 15.5,12A3.5,3.5 0 0,1 12,15.5M19.43,12.97C19.47,12.65 19.5,12.33 19.5,12C19.5,11.67 19.47,11.34 19.43,11L21.54,9.37C21.73,9.22 21.78,8.95 21.66,8.73L19.66,5.27C19.54,5.05 19.27,4.96 19.05,5.05L16.56,6.05C16.04,5.66 15.5,5.32 14.87,5.07L14.5,2.42C14.46,2.18 14.25,2 14,2H10C9.75,2 9.54,2.18 9.5,2.42L9.13,5.07C8.5,5.32 7.96,5.66 7.44,6.05L4.95,5.05C4.73,4.96 4.46,5.05 4.34,5.27L2.34,8.73C2.22,8.95 2.27,9.22 2.46,9.37L4.57,11C4.53,11.34 4.5,11.67 4.5,12C4.5,12.33 4.53,12.65 4.57,12.97L2.46,14.63C2.27,14.78 2.22,15.05 2.34,15.27L4.34,18.73C4.46,18.95 4.73,19.03 4.95,18.95L7.44,17.94C7.96,18.34 8.5,18.68 9.13,18.93L9.5,21.58C9.54,21.82 9.75,22 10,22H14C14.25,22 14.46,21.82 14.5,21.58L14.87,18.93C15.5,18.68 16.04,18.34 16.56,17.94L19.05,18.95C19.27,19.03 19.54,18.95 19.66,18.73L21.66,15.27C21.78,15.05 21.73,14.78 21.54,14.63L19.43,12.97Z"/>
                </svg>
                Layer-by-Layer Analysis
            </h2>
            
            <div class="model-layers" id="layerAnalysis">
                <div class="layer-header">
                    <div style="display: grid; grid-template-columns: 2fr 1fr 1fr 1fr; gap: 15px;">
                        <span>Layer</span>
                        <span>Parameters</span>
                        <span>Output Size</span>
                        <span>Memory (MB)</span>
                    </div>
                </div>
                <div style="color: #666; text-align: center; padding: 40px; font-style: italic;">
                    Run analysis to see layer details...
                </div>
            </div>
        </div>
    </div>

    <script>
        const templates = {
            gpt2: `import torch.nn as nn

class GPT2Large(nn.Module):
    def __init__(self, vocab_size=50257, d_model=1280, n_heads=20, n_layers=36, max_seq_len=1024):
        super().__init__()
        self.token_embedding = nn.Embedding(vocab_size, d_model)
        self.position_embedding = nn.Embedding(max_seq_len, d_model)
        
        self.transformer_blocks = nn.ModuleList([
            TransformerBlock(d_model, n_heads) for _ in range(n_layers)
        ])
        
        self.ln_final = nn.LayerNorm(d_model)
        self.head = nn.Linear(d_model, vocab_size)
    
    def forward(self, x):
        # GPT-2 Large: ~774M parameters
        # WARNING: Will likely exceed 16GB with large batch sizes
        pass

class TransformerBlock(nn.Module):
    def __init__(self, d_model, n_heads):
        super().__init__()
        self.attention = nn.MultiheadAttention(d_model, n_heads)
        self.feed_forward = nn.Sequential(
            nn.Linear(d_model, 4 * d_model),
            nn.GELU(),
            nn.Linear(4 * d_model, d_model)
        )
        self.ln1 = nn.LayerNorm(d_model)
        self.ln2 = nn.LayerNorm(d_model)`,

            vit: `import torch.nn as nn

class VisionTransformer(nn.Module):
    def __init__(self, img_size=384, patch_size=16, num_classes=1000, 
                 d_model=1024, n_heads=16, n_layers=24):
        super().__init__()
        self.patch_embed = nn.Conv2d(3, d_model, kernel_size=patch_size, stride=patch_size)
        num_patches = (img_size // patch_size) ** 2
        
        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))
        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, d_model))
        
        self.transformer = nn.ModuleList([
            nn.TransformerEncoderLayer(d_model, n_heads, d_model * 4) 
            for _ in range(n_layers)
        ])
        
        self.norm = nn.LayerNorm(d_model)
        self.head = nn.Linear(d_model, num_classes)
        
    def forward(self, x):
        # ViT-Large: ~307M parameters
        # High resolution images can cause OOM
        pass`,

            resnet: `import torch.nn as nn

class ResNet50(nn.Module):
    def __init__(self, num_classes=1000):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)
        self.bn1 = nn.BatchNorm2d(64)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        # ResNet blocks
        self.layer1 = self._make_layer(64, 64, 3)
        self.layer2 = self._make_layer(64, 128, 4, stride=2)  
        self.layer3 = self._make_layer(128, 256, 6, stride=2)
        self.layer4 = self._make_layer(256, 512, 3, stride=2)
        
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, num_classes)
        
    def _make_layer(self, in_planes, planes, blocks, stride=1):
        layers = []
        for _ in range(blocks):
            layers.append(nn.Conv2d(in_planes, planes, 3, stride, 1))
            layers.append(nn.BatchNorm2d(planes))
            layers.append(nn.ReLU(inplace=True))
            in_planes = planes
            stride = 1
        return nn.Sequential(*layers)
        
    def forward(self, x):
        # ResNet-50: ~25M parameters - should fit comfortably
        pass`,

            bert: `import torch.nn as nn

class BERTBase(nn.Module):
    def __init__(self, vocab_size=30522, d_model=768, n_heads=12, 
                 n_layers=12, max_seq_len=512):
        super().__init__()
        self.embeddings = nn.ModuleDict({
            'word_embeddings': nn.Embedding(vocab_size, d_model),
            'position_embeddings': nn.Embedding(max_seq_len, d_model),
            'token_type_embeddings': nn.Embedding(2, d_model)
        })
        
        self.encoder_layers = nn.ModuleList([
            nn.TransformerEncoderLayer(
                d_model=d_model,
                nhead=n_heads,
                dim_feedforward=d_model * 4,
                dropout=0.1
            ) for _ in range(n_layers)
        ])
        
        self.pooler = nn.Linear(d_model, d_model)
        self.classifier = nn.Linear(d_model, 2)  # Binary classification
        
    def forward(self, input_ids, attention_mask=None):
        # BERT-Base: ~110M parameters
        # Sequence length affects memory usage significantly
        pass`,

            lstm: `import torch.nn as nn

class LSTMModel(nn.Module):
    def __init__(self, vocab_size=10000, embed_dim=512, hidden_dim=1024, 
                 n_layers=4, num_classes=2):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        
        # Large LSTM layers
        self.lstm = nn.LSTM(
            embed_dim, 
            hidden_dim, 
            n_layers, 
            batch_first=True, 
            dropout=0.3,
            bidirectional=True
        )
        
        # Classification head
        self.dropout = nn.Dropout(0.5)
        self.fc1 = nn.Linear(hidden_dim * 2, 512)  # *2 for bidirectional
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, num_classes)
        
    def forward(self, x):
        # LSTM models can be memory intensive due to sequence processing
        # Long sequences with large hidden dimensions are problematic
        pass`
        };

        function loadTemplate(templateName) {
            document.getElementById('modelCode').value = templates[templateName];
            
            // Set appropriate defaults for each template
            const defaults = {
                gpt2: { batch: 4, input: '1024', precision: '16' },
                vit: { batch: 16, input: '3,384,384', precision: '16' },
                resnet: { batch: 64, input: '3,224,224', precision: '32' },
                bert: { batch: 16, input: '512', precision: '16' },
                lstm: { batch: 32, input: '256', precision: '32' }
            };
            
            if (defaults[templateName]) {
                document.getElementById('batchSize').value = defaults[templateName].batch;
                document.getElementById('inputSize').value = defaults[templateName].input;
                document.getElementById('precision').value = defaults[templateName].precision;
            }
        }

        function parseModelLayers(code) {
            const layers = [];
            
            // Simple regex patterns to extract layer information
            const patterns = {
                'Linear': /nn\.Linear\((\d+),\s*(\d+)\)/g,
                'Conv2d': /nn\.Conv2d\((\d+),\s*(\d+),\s*(?:kernel_size=)?(\d+)/g,
                'Conv1d': /nn\.Conv1d\((\d+),\s*(\d+),\s*(?:kernel_size=)?(\d+)/g,
                'Embedding': /nn\.Embedding\((\d+),\s*(\d+)\)/g,
                'LSTM': /nn\.LSTM\((\d+),\s*(\d+)(?:,\s*(\d+))?\)/g,
                'GRU': /nn\.GRU\((\d+),\s*(\d+)(?:,\s*(\d+))?\)/g,
                'TransformerEncoderLayer': /nn\.TransformerEncoderLayer\([^)]*d_model=(\d+)[^)]*nhead=(\d+)[^)]*dim_feedforward=(\d+)/g,
                'MultiheadAttention': /nn\.MultiheadAttention\((\d+),\s*(\d+)\)/g,
                'BatchNorm2d': /nn\.BatchNorm2d\((\d+)\)/g,
                'LayerNorm': /nn\.LayerNorm\((\d+)\)/g
            };

            for (const [layerType, pattern] of Object.entries(patterns)) {
                let match;
                while ((match = pattern.exec(code)) !== null) {
                    const params = match.slice(1).map(p => parseInt(p) || 0);
                    layers.push({ type: layerType, params: params });
                }
            }

            return layers;
        }

        function calculateLayerMemory(layer, batchSize, inputSize, precision) {
            const bytesPerParam = precision / 8;
            let paramCount = 0;
            let outputSize = [];
            let memoryMB = 0;

            const [channels, height, width] = inputSize.split(',').map(x => parseInt(x) || 1);
            
            switch (layer.type) {
                case 'Linear':
                    paramCount = layer.params[0] * layer.params[1] + layer.params[1]; // weights + bias
                    outputSize = [batchSize, layer.params[1]];
                    break;
                    
                case 'Conv2d':
                    const [inCh, outCh, kernel] = layer.params;
                    paramCount = inCh * outCh * kernel * kernel + outCh; // weights + bias
                    // Simplified output size calculation
                    outputSize = [batchSize, outCh, Math.floor(height/2), Math.floor(width/2)];
                    break;
                    
                case 'Embedding':
                    paramCount = layer.params[0] * layer.params[1];
                    outputSize = [batchSize, layer.params[1]];
                    break;
                    
                case 'LSTM':
                    const inputSize = layer.params[0];
                    const hiddenSize = layer.params[1];
                    const numLayers = layer.params[2] || 1;
                    // LSTM has 4 gates, each with input and hidden weights
                    paramCount = numLayers * 4 * (inputSize * hiddenSize + hiddenSize * hiddenSize + hiddenSize);
                    outputSize = [batchSize, hiddenSize];
                    break;
                    
                case 'TransformerEncoderLayer':
                    const dModel = layer.params[0];
                    const nHeads = layer.params[1];
                    const ffnDim = layer.params[2];
                    // Attention weights + FFN weights + layer norms
                    paramCount = 4 * dModel * dModel + 2 * dModel * ffnDim + 4 * dModel;
                    outputSize = [batchSize, dModel];
                    break;
                    
                case 'BatchNorm2d':
                case 'LayerNorm':
                    paramCount = layer.params[0] * 2; // scale + shift
                    break;
                    
                default:
                    paramCount = 1000; // Default estimate
            }

            memoryMB = (paramCount * bytesPerParam) / (1024 * 1024);
            
            return {
                paramCount,
                outputSize: outputSize.join('√ó'),
                memoryMB: memoryMB.toFixed(2)
            };
        }

        function analyzeModel() {
            const code = document.getElementById('modelCode').value;
            const batchSize = parseInt(document.getElementById('batchSize').value) || 32;
            const inputSize = document.getElementById('inputSize').value || '3,224,224';
            const precision = parseInt(document.getElementById('precision').value) || 32;

            if (!code.trim()) {
                alert('Please enter model code first!');
                return;
            }

            const layers = parseModelLayers(code);
            const bytesPerParam = precision / 8;

            let totalParams = 0;
            let layerAnalysisHTML = `
                <div class="layer-header">
                    <div style="display: grid; grid-template-columns: 2fr 1fr 1fr 1fr; gap: 15px;">
                        <span>Layer</span>
                        <span>Parameters</span>
                        <span>Output Size</span>
                        <span>Memory (MB)</span>
                    </div>
                </div>
            `;

            layers.forEach((layer, index) => {
                const analysis = calculateLayerMemory(layer, batchSize, inputSize, precision);
                totalParams += analysis.paramCount;
                
                layerAnalysisHTML += `
                    <div class="layer-item">
                        <span>${layer.type}_${index + 1}</span>
                        <span>${analysis.paramCount.toLocaleString()}</span>
                        <span>${analysis.outputSize}</span>
                        <span>${analysis.memoryMB}</span>
                    </div>
                `;
            });

            if (layers.length === 0) {
                // Estimate based on common patterns in code
                const lines = code.toLowerCase().split('\n');
                let estimatedParams = 0;
                
                lines.forEach(line => {
                    if (line.includes('linear') || line.includes('dense')) {
                        estimatedParams += 50000000; // 50M params estimate
                    } else if (line.includes('conv')) {
                        estimatedParams += 1000000; // 1M params estimate
                    } else if (line.includes('embedding')) {
                        estimatedParams += 10000000; // 10M params estimate
                    } else if (line.includes('transformer') || line.includes('attention')) {
                        estimatedParams += 100000000; // 100M params estimate
                    }
                });
                
                totalParams = Math.max(estimatedParams, 1000000); // At least 1M
                layerAnalysisHTML += `
                    <div style="color: #f39c12; text-align: center; padding: 20px; font-style: italic;">
                        Could not parse specific layers. Using estimated parameter count: ${totalParams.toLocaleString()}
                    </div>
                `;
            }

            // Memory calculations
            const paramMemoryMB = (totalParams * bytesPerParam) / (1024 * 1024);
            const gradMemoryMB = paramMemoryMB; // Same as parameters
            const optimMemoryMB = paramMemoryMB * 2; // Adam optimizer (momentum + variance)
            
            // Activation memory estimation (rough)
            const inputDims = inputSize.split(',').map(x => parseInt(x) || 1);
            const inputElements = inputDims.reduce((a, b) => a * b, batchSize);
            const activationMemoryMB = (inputElements * bytesPerParam * 10) / (1024 * 1024); // 10x multiplier for intermediate activations
            
            const totalMemoryMB = paramMemoryMB + gradMemoryMB + optimMemoryMB + activationMemoryMB;
            const totalMemoryGB = totalMemoryMB / 1024;

            // Update UI
            document.getElementById('paramMemory').textContent = `${paramMemoryMB.toFixed(1)} MB`;
            document.getElementById('gradMemory').textContent = `${gradMemoryMB.toFixed(1)} MB`;
            document.getElementById('optimMemory').textContent = `${optimMemoryMB.toFixed(1)} MB`;
            document.getElementById('activMemory').textContent = `${activationMemoryMB.toFixed(1)} MB`;
            document.getElementById('totalMemory').textContent = `${totalMemoryMB.toFixed(1)} MB (${totalMemoryGB.toFixed(2)} GB)`;

            // Progress bar and warnings
            const rtx5080MemoryGB = 16;
            const memoryUsagePercent = (totalMemoryGB / rtx5080MemoryGB) * 100;
            
            const progressBar = document.getElementById('memoryProgress');
            const warning = document.getElementById('warning');
            const success = document.getElementById('success');
            
            progressBar.style.width = `${Math.min(memoryUsagePercent, 100)}%`;
            progressBar.textContent = `${memoryUsagePercent.toFixed(1)}%`;
            
            if (memoryUsagePercent > 90) {
                progressBar.style.background = 'linear-gradient(45deg, #ff4444, #cc0000)';
                warning.style.display = 'block';
                success.style.display = 'none';
            } else if (memoryUsagePercent > 70) {
                progressBar.style.background = 'linear-gradient(45deg, #ffa500, #ff8c00)';
                warning.style.display = 'none';
                success.style.display = 'none';
            } else {
                progressBar.style.background = 'linear-gradient(45deg, #76b900, #a3d900)';
                warning.style.display = 'none';
                success.style.display = 'block';
            }

            document.getElementById('layerAnalysis').innerHTML = layerAnalysisHTML;
        }

        // Auto-analyze when template is loaded
        document.addEventListener('DOMContentLoaded', function() {
            // Load ResNet template by default
            loadTemplate('resnet');
        });
    </script>
</body>
</html>